@article{Liu1989,
abstract = {We study the numerical performance of a limited memory quasi-Newton method for large scale optimization, which we call the L-BFGS method. We compare its performance with that of the method developed by Buckley and LeNir (1985), which combines cycles of BFGS steps and conjugate direction steps. Our numerical tests indicate that the L-BFGS method is faster than the method of Buckley and LeNir, and is better able to use additional storage to accelerate convergence. We show that the L-BFGS method can be greatly accelerated by means of a simple scaling. We then compare the L-BFGS method with the partitioned quasi-Newton method of Griewank and Toint (1982a). The results show that, for some problems, the partitioned quasi-Newton method is clearly superior to the L-BFGS method. However we find that for other problems the L-BFGS method is very competitive due to its low iteration cost. We also study the convergence properties of the L-BFGS method, and prove global convergence on uniformly convex problems.},
author = {Liu, Dong C and Nocedal, Jorge},
doi = {10.1007/BF01589116},
issn = {00255610},
journal = {Mathematical Programming},
number = {1-3},
pages = {503--528},
publisher = {Springer},
title = {{On the limited memory BFGS method for large scale optimization}},
url = {http://www.springerlink.com/index/10.1007/BF01589116},
volume = {45},
year = {1989}
}
@book{boyd2004convex,
author = {{Boyd, S.P. and Vandenberghe}, L.},
publisher = {Cambridge Univ Pr},
title = {{Convex Optimization}},
year = {2004}
}
@article{Hindman2011,
abstract = {We present Mesos, a platform for sharing commodity clusters between multiple diverse cluster computing frameworks, such as Hadoop and MPI. Sharing improves cluster utilization and avoids per-framework data replication. Mesos shares resources in a fine-grained manner, allowing frameworks to achieve data locality by taking turns reading data stored on each machine. To support the sophisticated schedulers of today's frameworks, Mesos introduces a distributed two-level scheduling mechanism called resource offers. Mesos decides how many resources to offer each framework, while frameworks decide which resources to accept and which computations to run on them. Our experimental results show that Mesos can achieve near-optimal locality when sharing the cluster among diverse frameworks, can scale up to 50,000 nodes, and is resilient to node failures.},
author = {Hindman, Benjamin and Konwinski, Andy and Zaharia, Matei and Ghodsi, Ali and Joseph, Anthony D and Katz, Randy and Shenker, Scott and Stoica, Ion},
doi = {10.1109/tim.2009.2038002},
institution = {EECS Department, University of California, Berkeley},
issn = {00189456},
journal = {Architecture},
number = {UCB/EECS-2010-87},
pages = {22},
publisher = {USENIX Association},
title = {{Mesos : A Platform for Fine-Grained Resource Sharing in the Data Center}},
url = {http://www.usenix.org/events/nsdi11/tech/full\_papers/Hindman.pdf},
volume = {203},
year = {2011}
}
@article{Ghemawat2003,
abstract = {We have designed and implemented the Google File System, a scalable distributed file system for large distributed data-intensive applications. It provides fault tolerance while running on inexpensive commodity hardware, and it delivers high aggregate performance to a large number of clients. While sharing many of the same goals as previous distributed file systems, our design has been driven by observations of our application workloads and technological environment, both current and anticipated, that reflect a marked departure from some earlier file system assumptions. This has led us to reexamine traditional choices and explore radically different design points. The file system has successfully met our storage needs. It is widely deployed within Google as the storage platform for the generation and processing of data used by our service as well as research and development efforts that require large data sets. The largest cluster to date provides hundreds of terabytes of storage across thousands of disks on over a thousand machines, and it is concurrently accessed by hundreds of clients. In this paper, we present file system interface extensions designed to support distributed applications, discuss many aspects of our design, and report measurements from both micro-benchmarks and real world use.},
author = {Ghemawat, Sanjay and Gobioff, Howard and Leung, Shun-Tak},
doi = {10.1145/1165389.945450},
editor = {Roisin, C\'{e}cile and Munson, Ethan V and Vanoirbeek, Christine},
institution = {ACM},
isbn = {1581137575},
issn = {01635980},
journal = {ACM SIGOPS Operating Systems Review},
keywords = {clustered storage,data storage,fault tolerance,scalability},
number = {5},
pages = {29},
pmid = {191},
publisher = {ACM},
series = {SOSP '03},
title = {{The Google file system}},
url = {http://portal.acm.org/citation.cfm?doid=1165389.945450},
volume = {37},
year = {2003}
}
@article{Andrei2006,
abstract = {In this paper we introduce an acceleration of gradient descent algorithm with backtracking. The idea is to modify the steplength t k by means of a positive parameter $\theta$ k , in a multiplicative manner, in such a way to improve the behaviour of the classical gradient algorithm. It is shown that the resulting algorithm remains linear convergent, but the reduction in function value is significantly improved.},
author = {Andrei, Neculai},
doi = {10.1007/s11075-006-9023-9},
issn = {10171398},
journal = {Numerical Algorithms},
number = {1},
pages = {63--73},
publisher = {Springer U.S.},
title = {{An acceleration of gradient descent algorithm with backtracking for unconstrained optimization}},
url = {http://www.ingentaconnect.com/content/klu/numa/2006/00000042/00000001/00009023},
volume = {42},
year = {2006}
}
@article{King2001,
abstract = {We study rare events data, binary dependent variables with dozens to thousands of times fewer ones (events, such as wars, vetoes, cases of political activism, or epidemiological infections) than zeros ("nonevents"). In many literatures, these variables have proven difficult to explain and predict, a problem that seems to have at least two sources. First, popular statistical procedures, such as logistic regression, can sharply underestimate the probability of rare events. We recommend corrections that outperform existing methods and change the estimates of absolute and relative risks by as much as some estimated effects reported in the literature. Second, commonly used data collection strategies are grossly inefficient for rare events data. The fear of collecting data with too few events has led to data collections with huge numbers of observations but relatively few, and poorly measured, explanatory variables, such as in international conflict data with more than a quarter-million dyads, only a few of which are at war. As it turns out, more efficient sampling designs exist for making valid inferences, such as sampling all available events (e.g., wars) and a tiny fraction of nonevents (peace). This enables scholars to save as much as 99\% of their (nonfixed) data collection costs or to collect much more meaningful explanatory variables. We provide methods that link these two results, enabling both types of corrections to work simultaneously, and software that implements the methods developed.},
archivePrefix = {arXiv},
arxivId = {astro-ph/0212297},
author = {King, Gary and Zeng, Langche},
doi = {10.1086/345900},
eprint = {0212297},
institution = {Department of Government},
isbn = {1047198714764989},
issn = {10471987},
journal = {Political Analysis},
number = {2},
pages = {137--163},
primaryClass = {astro-ph},
publisher = {SPM-PMSAPSA},
series = {The Global Burden of Disease In Aging Populations},
title = {{Logistic Regression in Rare Events Data}},
url = {http://pan.oxfordjournals.org/cgi/content/abstract/9/2/137},
volume = {9},
year = {2001}
}
@article{Zaharia2010,
abstract = {MapReduce and its variants have been highly successful in implementing large-scale data intensive applications on clusters of unreliable machines. However, most of these systems are built around an acyclic data flow programming model that is not suitable for other popular applications. In this paper, we focus on one such class of applications: those that reuse a working set of data across multiple parallel operations. This includes many iterative machine learning algorithms, as well as interactive data analysis environments. We propose a new framework called Spark that supports these applications while maintaining the scalability and fault-tolerance properties of MapReduce. To achieve these goals, Spark introduces a data abstraction called resilient distributed datasets (RDDs). An RDD is a read-only collection of objects partitioned across a set of machines that can be rebuilt if a partition is lost. Spark can outperform Hadoop by 10x in iterative machine learning jobs, and can be used to interactively query a 39 GB dataset with sub-second response time.},
author = {Zaharia, Matei and Chowdhury, Mosharaf and Franklin, Michael J and Shenker, Scott and Stoica, Ion},
doi = {10.1007/s00256-009-0861-0},
institution = {EECS Department, University of California, Berkeley},
issn = {13669516},
journal = {Proceedings of the 2nd USENIX conference on Hot topics in cloud computing},
number = {UCB/EECS-2010-53},
pages = {10--10},
publisher = {USENIX Association},
series = {HotCloud'10},
title = {{Spark : Cluster Computing with Working Sets}},
url = {http://portal.acm.org/citation.cfm?id=1863113},
volume = {39},
year = {2010}
}
@article{Lewis2004,
abstract = {Reuters CorpusVolume I (RCV1) is an archive of over 800,000 manually categorized newswire stories recently made available by Reuters, Ltd. for research purposes. Use of this data for research on text categorization requires a detailed understanding of the real world constraints under which the data was produced. Drawing on interviews with Reuters personnel and access to Reuters doc- umentation, we describe the coding policy and quality control procedures used in producing the RCV1 data, the intended semantics of the hierarchical category taxonomies, and the corrections necessary to remove errorful data. We refer to the original data as RCV1-v1, and the corrected data as RCV1-v2. We benchmark several widely used supervised learning methods on RCV1-v2, illus- trating the collections properties, suggesting new directions for research, and providing baseline results for future studies. We make available detailed, per-category experimental results, as well as corrected versions of the category assignments and taxonomy structures, via online appendices.},
author = {Lewis, David D and Yang, Yiming and Rose, Tony G and Li, Fan},
doi = {10.1145/122860.122861},
file = {:Users/jdr/Library/Application Support/Mendeley Desktop/Downloaded/Lewis et al. - 2004 - RCV1 A New Benchmark Collection for Text Categorization Research.pdf:pdf},
isbn = {0897914481},
issn = {15337928},
journal = {Corpus},
pages = {361--397},
publisher = {JMLR. org},
title = {{RCV1: A New Benchmark Collection for Text Categorization Research}},
url = {http://portal.acm.org/citation.cfm?id=1005345},
volume = {5},
year = {2004}
}
@article{Dean2008,
author = {Dean, Jeffrey},
file = {:Users/jdr/Documents/School/papers/mapreduce-osdi04.pdf:pdf},
journal = {Communications of the ACM},
pages = {1--13},
title = {{MapReduce: Simplified data processing on large clusters}},
url = {http://dl.acm.org/citation.cfm?id=1327492},
year = {2008}
}
@article{Boyd2010a,
author = {Boyd, Stephen},
doi = {10.1561/2200000016},
file = {:Users/jdr/Documents/School/pdf textbooks/boyd - distributed optimization.pdf:pdf},
issn = {1935-8237},
journal = {Foundations and Trends® in Machine Learning},
number = {1},
pages = {1--122},
title = {{Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers}},
url = {http://www.nowpublishers.com/product.aspx?product=MAL\&doi=2200000016},
volume = {3},
year = {2010}
}
@article{Hunter2011,
address = {New York, New York, USA},
author = {Hunter, Timothy and Moldovan, Teodor and Zaharia, Matei and Merzgui, Samy and Ma, Justin and Franklin, Michael J. and Abbeel, Pieter and Bayen, Alexandre M.},
doi = {10.1145/2038916.2038944},
file = {:Users/jdr/Documents/School/papers/a28-hunter.pdf:pdf},
isbn = {9781450309769},
journal = {Proceedings of the 2nd ACM Symposium on Cloud Computing - SOCC '11},
pages = {1--8},
publisher = {ACM Press},
title = {{Scaling the mobile millennium system in the cloud}},
url = {http://dl.acm.org/citation.cfm?doid=2038916.2038944},
year = {2011}
}
